<<<<<<< HEAD
import inspect
import warnings

import numpy as np

from pandas._libs import reduction
=======
import abc
import inspect
from typing import TYPE_CHECKING, Any, Dict, Iterator, Tuple, Type, Union

import numpy as np

from pandas._libs import reduction as libreduction
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
from pandas.util._decorators import cache_readonly

from pandas.core.dtypes.common import (
    is_dict_like,
<<<<<<< HEAD
    is_extension_type,
=======
    is_extension_array_dtype,
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
    is_list_like,
    is_sequence,
)
from pandas.core.dtypes.generic import ABCSeries

<<<<<<< HEAD
from pandas.io.formats.printing import pprint_thing


def frame_apply(
    obj,
    func,
    axis=0,
    broadcast=None,
    raw=False,
    reduce=None,
    result_type=None,
    ignore_failures=False,
=======
from pandas.core.construction import create_series_with_explicit_dtype

if TYPE_CHECKING:
    from pandas import DataFrame, Series, Index

ResType = Dict[int, Any]


def frame_apply(
    obj: "DataFrame",
    func,
    axis=0,
    raw: bool = False,
    result_type=None,
    ignore_failures: bool = False,
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
    args=None,
    kwds=None,
):
    """ construct and return a row or column based frame apply object """

    axis = obj._get_axis_number(axis)
<<<<<<< HEAD
=======
    klass: Type[FrameApply]
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
    if axis == 0:
        klass = FrameRowApply
    elif axis == 1:
        klass = FrameColumnApply

    return klass(
        obj,
        func,
<<<<<<< HEAD
        broadcast=broadcast,
        raw=raw,
        reduce=reduce,
=======
        raw=raw,
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        result_type=result_type,
        ignore_failures=ignore_failures,
        args=args,
        kwds=kwds,
    )


<<<<<<< HEAD
class FrameApply:
    def __init__(
        self,
        obj,
        func,
        broadcast,
        raw,
        reduce,
        result_type,
        ignore_failures,
=======
class FrameApply(metaclass=abc.ABCMeta):

    # ---------------------------------------------------------------
    # Abstract Methods
    axis: int

    @property
    @abc.abstractmethod
    def result_index(self) -> "Index":
        pass

    @property
    @abc.abstractmethod
    def result_columns(self) -> "Index":
        pass

    @property
    @abc.abstractmethod
    def series_generator(self) -> Iterator["Series"]:
        pass

    @abc.abstractmethod
    def wrap_results_for_axis(
        self, results: ResType, res_index: "Index"
    ) -> Union["Series", "DataFrame"]:
        pass

    # ---------------------------------------------------------------

    def __init__(
        self,
        obj: "DataFrame",
        func,
        raw: bool,
        result_type,
        ignore_failures: bool,
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        args,
        kwds,
    ):
        self.obj = obj
        self.raw = raw
        self.ignore_failures = ignore_failures
        self.args = args or ()
        self.kwds = kwds or {}

        if result_type not in [None, "reduce", "broadcast", "expand"]:
            raise ValueError(
                "invalid value for result_type, must be one "
                "of {None, 'reduce', 'broadcast', 'expand'}"
            )

<<<<<<< HEAD
        if broadcast is not None:
            warnings.warn(
                "The broadcast argument is deprecated and will "
                "be removed in a future version. You can specify "
                "result_type='broadcast' to broadcast the result "
                "to the original dimensions",
                FutureWarning,
                stacklevel=4,
            )
            if broadcast:
                result_type = "broadcast"

        if reduce is not None:
            warnings.warn(
                "The reduce argument is deprecated and will "
                "be removed in a future version. You can specify "
                "result_type='reduce' to try to reduce the result "
                "to the original dimensions",
                FutureWarning,
                stacklevel=4,
            )
            if reduce:

                if result_type is not None:
                    raise ValueError("cannot pass both reduce=True and result_type")

                result_type = "reduce"

=======
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        self.result_type = result_type

        # curry if needed
        if (kwds or args) and not isinstance(func, (np.ufunc, str)):

            def f(x):
                return func(x, *args, **kwds)

        else:
            f = func

        self.f = f

<<<<<<< HEAD
        # results
        self.result = None
        self.res_index = None
        self.res_columns = None

    @property
    def columns(self):
        return self.obj.columns

    @property
    def index(self):
=======
    @property
    def res_columns(self) -> "Index":
        return self.result_columns

    @property
    def columns(self) -> "Index":
        return self.obj.columns

    @property
    def index(self) -> "Index":
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        return self.obj.index

    @cache_readonly
    def values(self):
        return self.obj.values

    @cache_readonly
<<<<<<< HEAD
    def dtypes(self):
        return self.obj.dtypes

    @property
    def agg_axis(self):
=======
    def dtypes(self) -> "Series":
        return self.obj.dtypes

    @property
    def agg_axis(self) -> "Index":
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        return self.obj._get_agg_axis(self.axis)

    def get_result(self):
        """ compute the results """

        # dispatch to agg
        if is_list_like(self.f) or is_dict_like(self.f):
            return self.obj.aggregate(self.f, axis=self.axis, *self.args, **self.kwds)

        # all empty
        if len(self.columns) == 0 and len(self.index) == 0:
            return self.apply_empty_result()

        # string dispatch
        if isinstance(self.f, str):
            # Support for `frame.transform('method')`
            # Some methods (shift, etc.) require the axis argument, others
            # don't, so inspect and insert if necessary.
            func = getattr(self.obj, self.f)
            sig = inspect.getfullargspec(func)
            if "axis" in sig.args:
                self.kwds["axis"] = self.axis
            return func(*self.args, **self.kwds)

        # ufunc
        elif isinstance(self.f, np.ufunc):
            with np.errstate(all="ignore"):
                results = self.obj._data.apply("apply", func=self.f)
            return self.obj._constructor(
                data=results, index=self.index, columns=self.columns, copy=False
            )

        # broadcasting
        if self.result_type == "broadcast":
<<<<<<< HEAD
            return self.apply_broadcast()
=======
            return self.apply_broadcast(self.obj)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        # one axis empty
        elif not all(self.obj.shape):
            return self.apply_empty_result()

        # raw
        elif self.raw and not self.obj._is_mixed_type:
            return self.apply_raw()

        return self.apply_standard()

    def apply_empty_result(self):
        """
        we have an empty result; at least 1 axis is 0

        we will try to apply the function to an empty
        series in order to see if this is a reduction function
        """

        # we are not asked to reduce or infer reduction
        # so just return a copy of the existing object
        if self.result_type not in ["reduce", None]:
            return self.obj.copy()

        # we may need to infer
<<<<<<< HEAD
        reduce = self.result_type == "reduce"

        from pandas import Series

        if not reduce:

            EMPTY_SERIES = Series([])
            try:
                r = self.f(EMPTY_SERIES, *self.args, **self.kwds)
                reduce = not isinstance(r, Series)
            except Exception:
                pass

        if reduce:
            return self.obj._constructor_sliced(np.nan, index=self.agg_axis)
=======
        should_reduce = self.result_type == "reduce"

        from pandas import Series

        if not should_reduce:
            try:
                r = self.f(Series([], dtype=np.float64))
            except Exception:
                pass
            else:
                should_reduce = not isinstance(r, Series)

        if should_reduce:
            if len(self.agg_axis):
                r = self.f(Series([], dtype=np.float64))
            else:
                r = np.nan

            return self.obj._constructor_sliced(r, index=self.agg_axis)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        else:
            return self.obj.copy()

    def apply_raw(self):
        """ apply to the values as a numpy array """
<<<<<<< HEAD

        try:
            result = reduction.reduce(self.values, self.f, axis=self.axis)
        except Exception:
=======
        try:
            result = libreduction.compute_reduction(self.values, self.f, axis=self.axis)
        except ValueError as err:
            if "Function does not reduce" not in str(err):
                # catch only ValueError raised intentionally in libreduction
                raise
            # We expect np.apply_along_axis to give a two-dimensional result, or
            #  also raise.
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
            result = np.apply_along_axis(self.f, self.axis, self.values)

        # TODO: mixed type case
        if result.ndim == 2:
            return self.obj._constructor(result, index=self.index, columns=self.columns)
        else:
            return self.obj._constructor_sliced(result, index=self.agg_axis)

<<<<<<< HEAD
    def apply_broadcast(self, target):
=======
    def apply_broadcast(self, target: "DataFrame") -> "DataFrame":
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        result_values = np.empty_like(target.values)

        # axis which we want to compare compliance
        result_compare = target.shape[0]

        for i, col in enumerate(target.columns):
            res = self.f(target[col])
            ares = np.asarray(res).ndim

            # must be a scalar or 1d
            if ares > 1:
                raise ValueError("too many dims to broadcast")
            elif ares == 1:

                # must match return dim
                if result_compare != len(res):
                    raise ValueError("cannot broadcast result")

            result_values[:, i] = res

        # we *always* preserve the original index / columns
        result = self.obj._constructor(
            result_values, index=target.index, columns=target.columns
        )
        return result

    def apply_standard(self):

        # try to reduce first (by default)
        # this only matters if the reduction in values is of different dtype
        # e.g. if we want to apply to a SparseFrame, then can't directly reduce

        # we cannot reduce using non-numpy dtypes,
        # as demonstrated in gh-12244
        if (
            self.result_type in ["reduce", None]
<<<<<<< HEAD
            and not self.dtypes.apply(is_extension_type).any()
        ):

            # Create a dummy Series from an empty array
            from pandas import Series

=======
            and not self.dtypes.apply(is_extension_array_dtype).any()
            # Disallow complex_internals since libreduction shortcut raises a TypeError
            and not self.agg_axis._has_complex_internals
        ):

>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
            values = self.values
            index = self.obj._get_axis(self.axis)
            labels = self.agg_axis
            empty_arr = np.empty(len(index), dtype=values.dtype)
<<<<<<< HEAD
            dummy = Series(empty_arr, index=index, dtype=values.dtype)

            try:
                result = reduction.reduce(
                    values, self.f, axis=self.axis, dummy=dummy, labels=labels
                )
                return self.obj._constructor_sliced(result, index=labels)
            except Exception:
                pass

        # compute the result using the series generator
        self.apply_series_generator()

        # wrap results
        return self.wrap_results()

    def apply_series_generator(self):
        series_gen = self.series_generator
        res_index = self.result_index

        i = None
=======

            # Preserve subclass for e.g. test_subclassed_apply
            dummy = self.obj._constructor_sliced(
                empty_arr, index=index, dtype=values.dtype
            )

            try:
                result = libreduction.compute_reduction(
                    values, self.f, axis=self.axis, dummy=dummy, labels=labels
                )
            except ValueError as err:
                if "Function does not reduce" not in str(err):
                    # catch only ValueError raised intentionally in libreduction
                    raise
            except TypeError:
                # e.g. test_apply_ignore_failures we just ignore
                if not self.ignore_failures:
                    raise
            except ZeroDivisionError:
                # reached via numexpr; fall back to python implementation
                pass
            else:
                return self.obj._constructor_sliced(result, index=labels)

        # compute the result using the series generator
        results, res_index = self.apply_series_generator()

        # wrap results
        return self.wrap_results(results, res_index)

    def apply_series_generator(self) -> Tuple[ResType, "Index"]:
        series_gen = self.series_generator
        res_index = self.result_index

>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        keys = []
        results = {}
        if self.ignore_failures:
            successes = []
            for i, v in enumerate(series_gen):
                try:
                    results[i] = self.f(v)
<<<<<<< HEAD
                    keys.append(v.name)
                    successes.append(i)
                except Exception:
                    pass
=======
                except Exception:
                    pass
                else:
                    keys.append(v.name)
                    successes.append(i)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

            # so will work with MultiIndex
            if len(successes) < len(res_index):
                res_index = res_index.take(successes)

        else:
<<<<<<< HEAD
            try:
                for i, v in enumerate(series_gen):
                    results[i] = self.f(v)
                    keys.append(v.name)
            except Exception as e:
                if hasattr(e, "args"):

                    # make sure i is defined
                    if i is not None:
                        k = res_index[i]
                        e.args = e.args + ("occurred at index %s" % pprint_thing(k),)
                raise

        self.results = results
        self.res_index = res_index
        self.res_columns = self.result_columns

    def wrap_results(self):
        results = self.results

        # see if we can infer the results
        if len(results) > 0 and is_sequence(results[0]):

            return self.wrap_results_for_axis()

        # dict of scalars
        result = self.obj._constructor_sliced(results)
        result.index = self.res_index
=======
            for i, v in enumerate(series_gen):
                results[i] = self.f(v)
                keys.append(v.name)

        return results, res_index

    def wrap_results(
        self, results: ResType, res_index: "Index"
    ) -> Union["Series", "DataFrame"]:
        from pandas import Series

        # see if we can infer the results
        if len(results) > 0 and 0 in results and is_sequence(results[0]):

            return self.wrap_results_for_axis(results, res_index)

        # dict of scalars

        # the default dtype of an empty Series will be `object`, but this
        # code can be hit by df.mean() where the result should have dtype
        # float64 even if it's an empty Series.
        constructor_sliced = self.obj._constructor_sliced
        if constructor_sliced is Series:
            result = create_series_with_explicit_dtype(
                results, dtype_if_empty=np.float64
            )
        else:
            result = constructor_sliced(results)
        result.index = res_index
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        return result


class FrameRowApply(FrameApply):
    axis = 0

<<<<<<< HEAD
    def apply_broadcast(self):
        return super().apply_broadcast(self.obj)
=======
    def apply_broadcast(self, target: "DataFrame") -> "DataFrame":
        return super().apply_broadcast(target)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

    @property
    def series_generator(self):
        return (self.obj._ixs(i, axis=1) for i in range(len(self.columns)))

    @property
<<<<<<< HEAD
    def result_index(self):
        return self.columns

    @property
    def result_columns(self):
        return self.index

    def wrap_results_for_axis(self):
        """ return the results for the rows """

        results = self.results
        result = self.obj._constructor(data=results)

        if not isinstance(results[0], ABCSeries):
            try:
                result.index = self.res_columns
            except ValueError:
                pass

        try:
            result.columns = self.res_index
        except ValueError:
            pass
=======
    def result_index(self) -> "Index":
        return self.columns

    @property
    def result_columns(self) -> "Index":
        return self.index

    def wrap_results_for_axis(
        self, results: ResType, res_index: "Index"
    ) -> "DataFrame":
        """ return the results for the rows """

        result = self.obj._constructor(data=results)

        if not isinstance(results[0], ABCSeries):
            if len(result.index) == len(self.res_columns):
                result.index = self.res_columns

        if len(result.columns) == len(res_index):
            result.columns = res_index
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        return result


class FrameColumnApply(FrameApply):
    axis = 1

<<<<<<< HEAD
    def apply_broadcast(self):
        result = super().apply_broadcast(self.obj.T)
=======
    def apply_broadcast(self, target: "DataFrame") -> "DataFrame":
        result = super().apply_broadcast(target.T)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f
        return result.T

    @property
    def series_generator(self):
        constructor = self.obj._constructor_sliced
        return (
            constructor(arr, index=self.columns, name=name)
            for i, (arr, name) in enumerate(zip(self.values, self.index))
        )

    @property
<<<<<<< HEAD
    def result_index(self):
        return self.index

    @property
    def result_columns(self):
        return self.columns

    def wrap_results_for_axis(self):
        """ return the results for the columns """
        results = self.results

        # we have requested to expand
        if self.result_type == "expand":
            result = self.infer_to_same_shape()
=======
    def result_index(self) -> "Index":
        return self.index

    @property
    def result_columns(self) -> "Index":
        return self.columns

    def wrap_results_for_axis(
        self, results: ResType, res_index: "Index"
    ) -> Union["Series", "DataFrame"]:
        """ return the results for the columns """
        result: Union["Series", "DataFrame"]

        # we have requested to expand
        if self.result_type == "expand":
            result = self.infer_to_same_shape(results, res_index)
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        # we have a non-series and don't want inference
        elif not isinstance(results[0], ABCSeries):
            from pandas import Series

            result = Series(results)
<<<<<<< HEAD
            result.index = self.res_index

        # we may want to infer results
        else:
            result = self.infer_to_same_shape()

        return result

    def infer_to_same_shape(self):
        """ infer the results to the same shape as the input object """
        results = self.results
=======
            result.index = res_index

        # we may want to infer results
        else:
            result = self.infer_to_same_shape(results, res_index)

        return result

    def infer_to_same_shape(self, results: ResType, res_index: "Index") -> "DataFrame":
        """ infer the results to the same shape as the input object """
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        result = self.obj._constructor(data=results)
        result = result.T

        # set the index
<<<<<<< HEAD
        result.index = self.res_index
=======
        result.index = res_index
>>>>>>> 08cf566694c2c63d615f5d40137fa82e6bddcc6f

        # infer dtypes
        result = result.infer_objects()

        return result
